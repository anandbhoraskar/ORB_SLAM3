{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from bisect import bisect\n",
    "np.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /media/prakhar/BIG_BAG/Capstone/office/office1-7\n"
     ]
    }
   ],
   "source": [
    "scene = \"office\"\n",
    "sequence= 7\n",
    "sample = scene+\"1-\"+str(sequence)\n",
    "\n",
    "\n",
    "inpath = os.path.join(\"/media/prakhar/BIG_BAG/Capstone/\"+scene, sample)\n",
    "print(\"Loading dataset from: \"+inpath)\n",
    "assert os.path.exists(inpath), \"Path DNE: \"+inpath\n",
    "\n",
    "f1path = os.path.join(inpath,\"fisheye1.txt\")\n",
    "f2path = os.path.join(inpath,\"fisheye2.txt\")\n",
    "\n",
    "depthpath = os.path.join(inpath,\"depth.txt\")\n",
    "gyropath = os.path.join(inpath,\"t265_gyroscope.txt\")\n",
    "accpath = os.path.join(inpath,\"t265_accelerometer.txt\")\n",
    "\n",
    "outpath = \"/media/prakhar/BIG_BAG/Capstone/Loris_stereoi/\"+sample\n",
    "#associations file\n",
    "\n",
    "sensorpath = \"/media/prakhar/BIG_BAG/Capstone/\"+scene+\"/\"+sample+\"/sensors.yaml\"\n",
    "matpath = \"/media/prakhar/BIG_BAG/Capstone/\"+scene+\"/\"+sample+\"/trans_matrix.yaml\"\n",
    "\n",
    "timestamp_dir = \"/home/prakhar/CMU/Capstone/code/ORB_SLAM3/Examples/Stereo-Inertial/Loris_TimeStamps/\"\n",
    "timestamp_path = os.path.join(timestamp_dir, sample+\".txt\")\n",
    "\n",
    "imu_dir = \"/home/prakhar/CMU/Capstone/code/ORB_SLAM3/Examples/Stereo-Inertial/Loris_IMU/\"\n",
    "imu_path = os.path.join(imu_dir, sample+\".txt\")\n",
    "\n",
    "if not os.path.exists(timestamp_dir):\n",
    "    os.mkdir(timestamp_dir)\n",
    "if not os.path.exists(imu_dir):\n",
    "    os.mkdir(imu_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = cv2.FileStorage(sensorpath, cv2.FILE_STORAGE_READ)\n",
    "mat_data = cv2.FileStorage(matpath, cv2.FILE_STORAGE_READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4) (3, 4)\n",
      "[[ 1.0138926506  0.            0.           -0.051095333 ]\n",
      " [ 0.            1.0174480677  0.            0.2732152045]\n",
      " [ 0.            0.            1.0285693407  0.094960019 ]]\n",
      "[[0.9956794977 0.           0.           0.0019203491]\n",
      " [0.           0.9980374575 0.           0.0021561817]\n",
      " [0.           0.           0.9926954508 0.0011997448]]\n",
      "noise_acc_std [0.0081824478 0.0081824478 0.0081824478]\n",
      "noise_gyro_std [0.0022689271 0.0022689271 0.0022689271]\n",
      "bias_acc_std [0.0099999999 0.0099999999 0.0099999999]\n",
      "bias_gyro_std [0.0007071068 0.0007071068 0.0007071068]\n"
     ]
    }
   ],
   "source": [
    "intr_acc = sensor_data.getNode(\"t265_accelerometer\").getNode(\"imu_intrinsic\").mat().reshape(3,4)\n",
    "intr_gyro = sensor_data.getNode(\"t265_gyroscope\").getNode(\"imu_intrinsic\").mat().reshape(3,4)\n",
    "print(intr_acc.shape, intr_gyro.shape)\n",
    "print(intr_acc)\n",
    "print(intr_gyro)\n",
    "\n",
    "#all the noise values are variances while we need std\n",
    "noise_acc = sensor_data.getNode(\"t265_accelerometer\").getNode(\"noise_variances\").mat().reshape(3,)\n",
    "print(\"noise_acc_std\",np.sqrt(noise_acc))\n",
    "noise_gyro = sensor_data.getNode(\"t265_gyroscope\").getNode(\"noise_variances\").mat().reshape(3,)\n",
    "print(\"noise_gyro_std\",np.sqrt(noise_gyro))\n",
    "bias_acc = sensor_data.getNode(\"t265_accelerometer\").getNode(\"bias_variances\").mat().reshape(3,)\n",
    "print(\"bias_acc_std\",np.sqrt(bias_acc))\n",
    "bias_gyro = sensor_data.getNode(\"t265_gyroscope\").getNode(\"bias_variances\").mat().reshape(3,)\n",
    "print(\"bias_gyro_std\",np.sqrt(bias_gyro))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_block(block):\n",
    "    k1 = block[0].split(\": \")[1]\n",
    "    k2 = block[1].split(\": \")[1]\n",
    "    k3 = \"\".join(block[6:13]).replace(\" \", \"\").split(\"data:\")[1].replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "    k3 = np.array([float(l) for l in k3]).reshape((4,4))\n",
    "    return k1,k2,k3\n",
    "\n",
    "def get_trans_mats(matpath):\n",
    "    with open(matpath,\"r\") as fp:\n",
    "        data = [l[:-1] for l in fp.readlines()]\n",
    "    # print(data)\n",
    "    ls_blocks = []\n",
    "    lsl = None\n",
    "    for l in data:\n",
    "        if '   -' == l:\n",
    "            if lsl is not None:\n",
    "                ls_blocks.append(lsl)\n",
    "            lsl = []\n",
    "        else:\n",
    "            if lsl is not None:\n",
    "                lsl.append(l)\n",
    "    if lsl is not None:\n",
    "        ls_blocks.append(lsl)\n",
    "    ls_blocks = [parse_block(block) for block in ls_blocks]\n",
    "    dict_trans = dict()\n",
    "    for block in ls_blocks:\n",
    "        k1,k2,k3 = block\n",
    "        print(k1)\n",
    "        dict_trans[k1] = dict()\n",
    "    for block in ls_blocks:\n",
    "        k1,k2,k3 = block\n",
    "        dict_trans[k1][k2] = k3\n",
    "    return dict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_link\n",
      "base_link\n",
      "base_link\n",
      "d400_color_optical_frame\n",
      "d400_color_optical_frame\n",
      "d400_color_optical_frame\n",
      "t265_fisheye1_optical_frame\n",
      "t265_fisheye1_optical_frame\n",
      "t265_fisheye1_optical_frame\n"
     ]
    }
   ],
   "source": [
    "dict_trans = get_trans_mats(matpath)\n",
    "extr_acc = dict_trans['t265_fisheye1_optical_frame']['t265_accelerometer']\n",
    "extr_gyro = dict_trans['t265_fisheye1_optical_frame']['t265_gyroscope']\n",
    "extr_stereo = dict_trans['t265_fisheye1_optical_frame']['t265_fisheye2_optical_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.9992633142e-01  4.9341275781e-03  1.1089910930e-02  1.0699998587e-02]\n",
      " [-4.9039224757e-03 -9.9998419659e-01  2.7492007439e-03  7.2759576142e-12]\n",
      " [ 1.1103300579e-02  2.6946141507e-03  9.9993472576e-01 -2.9103830457e-11]\n",
      " [ 0.0000000000e+00  0.0000000000e+00  0.0000000000e+00  1.0000000000e+00]]\n",
      "[[-9.9992633142e-01  4.9341275781e-03  1.1089910930e-02  1.0699998587e-02]\n",
      " [-4.9039224757e-03 -9.9998419659e-01  2.7492007439e-03  7.2759576142e-12]\n",
      " [ 1.1103300579e-02  2.6946141507e-03  9.9993472576e-01 -2.9103830457e-11]\n",
      " [ 0.0000000000e+00  0.0000000000e+00  0.0000000000e+00  1.0000000000e+00]]\n",
      "[[ 9.9997103352e-01 -3.0859078733e-03  6.9576787768e-03  6.3976511359e-02]\n",
      " [ 3.1121161182e-03  9.9998809175e-01 -3.7591338255e-03  1.4826713595e-04]\n",
      " [-6.9459955824e-03  3.7806780409e-03  9.9996872932e-01 -3.9846837171e-04]\n",
      " [ 0.0000000000e+00  0.0000000000e+00  0.0000000000e+00  1.0000000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(extr_acc)\n",
    "print(extr_gyro)\n",
    "print(extr_stereo)\n",
    "assert np.allclose(extr_acc, extr_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerometrer extrisic matrix:\n",
      " [-0.9999263314167736, -0.004903922475695184, 0.011103300578872334, 0.010699210334022371, 0.004934127578069439, -0.999984196594937, 0.002694614150708582, -5.2795150761128155e-05, 0.011089910930018767, 0.0027492007438955656, 0.9999347257550536, -0.00011866200220366497, 0.0, 0.0, 0.0, 1.0]\n",
      "right frame to left frame extrinsic matrix:\n",
      " [0.9999710335197896, -0.003085907873266471, 0.006957678776835974, 0.0639765113592, 0.003112116118197612, 0.9999880917521713, -0.0037591338254934705, 0.000148267135955, -0.006945995582404035, 0.0037806780408845384, 0.9999687293205325, -0.000398468371714, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# extr_acc_inv = np.linalg.inv(extr_acc).flatten()\n",
    "# print(list(extr_acc_inv))\n",
    "# extr_stereo_inv = np.linalg.inv(extr_stereo).flatten()\n",
    "# print(list(extr_stereo_inv))\n",
    "print(\"accelerometrer extrisic matrix:\\n\",list(np.linalg.inv(extr_acc).flatten()))\n",
    "\n",
    "print(\"right frame to left frame extrinsic matrix:\\n\",list(extr_stereo.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_data(rgbpath):\n",
    "    with open(rgbpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "        data = [[float(l[0]), l[0], l[1]] for l in data]\n",
    "    return data\n",
    "\n",
    "def get_aligned_depth_data(depthpath):\n",
    "    with open(depthpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "        data = [[float(l[0]), l[0], 'aligned_'+l[1]] for l in data]\n",
    "    return data\n",
    "\n",
    "def get_gyroscope_data(gyropath, intr_gyro):\n",
    "    with open(gyropath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "    head = data[0]\n",
    "    data = data[1:]\n",
    "    data = np.array([np.array([float(k) for k in l]) for l in data])\n",
    "    datam = data[:,1:]\n",
    "    data_scaled = np.transpose(intr_gyro[:3,:3]@datam.T) - intr_gyro[:,3]\n",
    "    data[:,1:] = data_scaled\n",
    "    return head, data\n",
    "    \n",
    "def get_accelerometer_data(accpath, intr_acc):\n",
    "    with open(accpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "    head = data[0]\n",
    "    data = data[1:]\n",
    "    data = np.array([np.array([float(k) for k in l]) for l in data])\n",
    "    datam = data[:,1:]\n",
    "    data_scaled = np.transpose(intr_acc[:3,:3]@datam.T) - intr_acc[:,3]\n",
    "    data[:,1:] = data_scaled\n",
    "    return head, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#Time', 'Gx', 'Gy', 'Gz'] (3789, 4)\n",
      "['#Time', 'Ax', 'Ay', 'Az'] (2368, 4)\n"
     ]
    }
   ],
   "source": [
    "head, data_gyro = get_gyroscope_data(gyropath, intr_gyro)\n",
    "#take every alternate row of gyro data\n",
    "data_gyro = data_gyro[::2]\n",
    "print(head, data_gyro.shape)\n",
    "head, data_acc = get_accelerometer_data(accpath, intr_acc)\n",
    "print(head, data_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_max = bisect(data_gyro[:,0], data_acc[-1,0])\n",
    "ind_min = bisect(data_gyro[:,0], data_acc[0,0])\n",
    "data_gyro = data_gyro[ind_min:ind_max,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gyro freq:  99.77610285756697\n",
      "accelereometer freq:  62.35476696186154\n"
     ]
    }
   ],
   "source": [
    "print(\"Gyro freq: \",100/(data_gyro[100,0] - data_gyro[0,0]))\n",
    "print(\"accelereometer freq: \", 100/(data_acc[100,0] - data_acc[0,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create interpolators\n",
    "acc_interpolator = interp1d(data_acc[:,0], data_acc[:,1:], axis=0)\n",
    "#interpolate at precise timesteps\n",
    "acc_interp = acc_interpolator(data_gyro[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Creating dir: /media/prakhar/BIG_BAG/Capstone/Loris_stereoi/office1-7/mav0/imu0/\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def write_IMU_readings(head, imu_mat, imu_path):\n",
    "    with open(imu_path, \"w\") as fp:\n",
    "        fp.write(head)\n",
    "        for idr in range(imu_mat.shape[0]):\n",
    "            reading = imu_mat[idr]\n",
    "            ts = str(int(reading[0]))\n",
    "            lsr = [str(x) for x in reading[1:]]\n",
    "            lsr = [ts] + lsr\n",
    "            line = \",\".join(lsr) + \"\\n\"\n",
    "            fp.write(line)\n",
    "    print(\"Done.\")\n",
    "\n",
    "#imu hed\n",
    "head = \"#timestamp [ns],w_RS_S_x [rad s^-1],w_RS_S_y [rad s^-1],w_RS_S_z [rad s^-1],a_RS_S_x [m s^-2],a_RS_S_y [m s^-2],a_RS_S_z [m s^-2]\\n\"\n",
    "imu_mat = np.concatenate([data_gyro, acc_interp], axis=1)\n",
    "imu_mat[:,0] *= 1e9\n",
    "\n",
    "write_IMU_readings(head, imu_mat, imu_path)\n",
    "\n",
    "imu_dir2 = os.path.join(outpath, \"mav0/imu0/\")\n",
    "\n",
    "if not os.path.exists(imu_dir2):\n",
    "    print(\"Creating dir: \"+imu_dir2)\n",
    "    os.makedirs(imu_dir2)\n",
    "\n",
    "imu_path2 = os.path.join(imu_dir2, \"data.csv\")\n",
    "write_IMU_readings(head, imu_mat, imu_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5602449571e+18  5.5045114927e-03 -2.9769236003e-05  1.9728016232e-03\n",
      "   1.2864987776e-01  9.7632174133e+00 -3.6710935683e-01]\n",
      " [ 1.5602449571e+18  2.0103955497e-04 -2.1561817266e-03  1.9728016232e-03\n",
      "   1.2864987776e-01  9.7510566988e+00 -3.5481577649e-01]\n",
      " [ 1.5602449572e+18 -1.9203490810e-03 -8.5354194308e-03 -1.1997447582e-03\n",
      "   1.3667183657e-01  9.7469467192e+00 -3.6693706107e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(imu_mat[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f1 = get_rgb_data(f1path)\n",
    "data_f2 = get_rgb_data(f2path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset to be written at: /media/prakhar/BIG_BAG/Capstone/Loris_stereoi/office1-7\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset to be written at: \"+outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: /media/prakhar/BIG_BAG/Capstone/Loris_stereoi/office1-7/mav0/cam0/data/\n",
      "Creating dir: /media/prakhar/BIG_BAG/Capstone/Loris_stereoi/office1-7/mav0/cam1/data/\n"
     ]
    }
   ],
   "source": [
    "cam_path1 = os.path.join(outpath, \"mav0/cam0/data/\")\n",
    "if not os.path.exists(cam_path1):\n",
    "    print(\"Creating dir: \"+cam_path1)\n",
    "    os.makedirs(cam_path1)\n",
    "cam_path2 = os.path.join(outpath, \"mav0/cam1/data/\")\n",
    "if not os.path.exists(cam_path2):\n",
    "    print(\"Creating dir: \"+cam_path2)\n",
    "    os.makedirs(cam_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1140\n",
      "200 1140\n",
      "300 1140\n",
      "400 1140\n",
      "500 1140\n",
      "600 1140\n",
      "700 1140\n",
      "800 1140\n",
      "900 1140\n",
      "1000 1140\n",
      "1100 1140\n"
     ]
    }
   ],
   "source": [
    "with open(timestamp_path, \"w\") as fp:\n",
    "    for idx,(line1, line2) in enumerate(zip(data_f1, data_f2)):\n",
    "        if line1[1] != line2[1]:\n",
    "            print(\"Not same!!: \", line1[1], line2[1])\n",
    "            continue\n",
    "        \n",
    "        tsstr = str(int(line1[0]*1e9))\n",
    "        \n",
    "        fp.write(tsstr+\"\\n\")\n",
    "        fname = tsstr+\".png\"\n",
    "        dst1 = os.path.join(cam_path1, fname)\n",
    "        dst2 = os.path.join(cam_path2, fname)\n",
    "        \n",
    "        src1 = os.path.join(inpath, line1[2])\n",
    "        src2 = os.path.join(inpath, line2[2])\n",
    "        command1 = \"ln -sf \"+src1+\" \"+dst1\n",
    "        command2 = \"ln -sf \"+src2+\" \"+dst2\n",
    "#         print(command1)\n",
    "#         print(command2)\n",
    "#         break\n",
    "        os.system(command1)\n",
    "        os.system(command2)\n",
    "        if (idx+1)%100 == 0:\n",
    "            print(idx+1,len(data_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/media/prakhar/BIG_BAG/Capstone/office/office1-1/fisheye1/1560000083.949067.png\"\n",
    "\"/media/prakhar/BIG_BAG/Capstone/office/office1-1/fisheye2/1560000083.949067.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viPy3_CMU",
   "language": "python",
   "name": "vipy3_cmu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
