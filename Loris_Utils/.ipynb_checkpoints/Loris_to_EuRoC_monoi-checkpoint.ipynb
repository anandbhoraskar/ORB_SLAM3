{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"office1-6\"\n",
    "inpath = os.path.join(\"/media/prakhar/BIG_BAG/Capstone/office\", sample)\n",
    "\n",
    "rgbpath = os.path.join(inpath,\"color.txt\")\n",
    "depthpath = os.path.join(inpath,\"depth.txt\")\n",
    "gyropath = os.path.join(inpath,\"d400_gyroscope.txt\")\n",
    "accpath = os.path.join(inpath,\"d400_accelerometer.txt\")\n",
    "\n",
    "\n",
    "assoc_path = \"/home/prakhar/CMU/Capstone/code/ORB_SLAM3/Examples/Monocular-Inertial/\"\n",
    "\n",
    "outpath = \"/media/prakhar/BIG_BAG/Capstone/Loris_monoi/\"+sample\n",
    "#associations file\n",
    "\n",
    "sensorpath = \"/media/prakhar/BIG_BAG/Capstone/office/\"+sample+\"/sensors.yaml\"\n",
    "matpath = \"/media/prakhar/BIG_BAG/Capstone/office/\"+sample+\"/trans_matrix.yaml\"\n",
    "\n",
    "timestamp_dir = \"/home/prakhar/CMU/Capstone/code/ORB_SLAM3/Examples/Monocular-Inertial/Loris_TimeStamps/\"\n",
    "timestamp_path = os.path.join(timestamp_dir, sample+\".txt\")\n",
    "\n",
    "imu_dir = \"/home/prakhar/CMU/Capstone/code/ORB_SLAM3/Examples/Monocular-Inertial/Loris_IMU/\"\n",
    "imu_path = os.path.join(imu_dir, sample+\".txt\")\n",
    "\n",
    "if not os.path.exists(timestamp_dir):\n",
    "    os.mkdir(timestamp_dir)\n",
    "if not os.path.exists(imu_dir):\n",
    "    os.mkdir(imu_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = cv2.FileStorage(sensorpath, cv2.FILE_STORAGE_READ)\n",
    "mat_data = cv2.FileStorage(matpath, cv2.FILE_STORAGE_READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intr_acc = sensor_data.getNode(\"d400_accelerometer\").getNode(\"imu_intrinsic\").mat().reshape(3,4)\n",
    "intr_gyro = sensor_data.getNode(\"d400_gyroscope\").getNode(\"imu_intrinsic\").mat().reshape(3,4)\n",
    "print(intr_acc.shape, intr_gyro.shape)\n",
    "print(intr_acc)\n",
    "print(intr_gyro)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_block(block):\n",
    "    k1 = block[0].split(\": \")[1]\n",
    "    k2 = block[1].split(\": \")[1]\n",
    "    k3 = \"\".join(block[6:13]).replace(\" \", \"\").split(\"data:\")[1].replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "    k3 = np.array([float(l) for l in k3]).reshape((4,4))\n",
    "    return k1,k2,k3\n",
    "\n",
    "def get_trans_mats(matpath):\n",
    "    with open(matpath,\"r\") as fp:\n",
    "        data = [l[:-1] for l in fp.readlines()]\n",
    "    # print(data)\n",
    "    ls_blocks = []\n",
    "    lsl = None\n",
    "    for l in data:\n",
    "        if '   -' == l:\n",
    "            if lsl is not None:\n",
    "                ls_blocks.append(lsl)\n",
    "            lsl = []\n",
    "        else:\n",
    "            if lsl is not None:\n",
    "                lsl.append(l)\n",
    "    if lsl is not None:\n",
    "        ls_blocks.append(lsl)\n",
    "\n",
    "    ls_blocks = [parse_block(block) for block in ls_blocks]\n",
    "    dict_trans = dict()\n",
    "    for block in ls_blocks:\n",
    "        k1,k2,k3 = block\n",
    "        print(k1)\n",
    "        dict_trans[k1] = dict()\n",
    "    for block in ls_blocks:\n",
    "        k1,k2,k3 = block\n",
    "        dict_trans[k1][k2] = k3\n",
    "    return dict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0859db4ae68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trans_mats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mextr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_trans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd400_color_optical_frame'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd400_accelerometer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextr_gyro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_trans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd400_color_optical_frame'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd400_gyroscope'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matpath' is not defined"
     ]
    }
   ],
   "source": [
    "dict_trans = get_trans_mats(matpath)\n",
    "extr_acc = dict_trans['d400_color_optical_frame']['d400_accelerometer']\n",
    "extr_gyro = dict_trans['d400_color_optical_frame']['d400_gyroscope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extr_acc)\n",
    "print(extr_gyro)\n",
    "\n",
    "assert np.allclose(extr_acc, extr_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_data(rgbpath):\n",
    "    with open(rgbpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "        data = [[float(l[0]), l[0], l[1]] for l in data]\n",
    "    return data\n",
    "\n",
    "def get_aligned_depth_data(depthpath):\n",
    "    with open(depthpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "        data = [[float(l[0]), l[0], 'aligned_'+l[1]] for l in data]\n",
    "    return data\n",
    "\n",
    "def get_gyroscope_data(gyropath, intr_gyro):\n",
    "    with open(gyropath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "    head = data[0]\n",
    "    data = data[1:]\n",
    "    data = np.array([np.array([float(k) for k in l]) for l in data])\n",
    "    datam = data[:,1:]\n",
    "    data_scaled = np.transpose(intr_gyro[:3,:3]@datam.T) - intr_gyro[:,3]\n",
    "    data[:,1:] = data_scaled\n",
    "    return head, data\n",
    "    \n",
    "def get_accelerometer_data(accpath, intr_acc):\n",
    "    with open(accpath, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "        data = [l[:-1].split(\" \") for l in data]\n",
    "    head = data[0]\n",
    "    data = data[1:]\n",
    "    data = np.array([np.array([float(k) for k in l]) for l in data])\n",
    "    datam = data[:,1:]\n",
    "    data_scaled = np.transpose(intr_acc[:3,:3]@datam.T) - intr_acc[:,3]\n",
    "    data[:,1:] = data_scaled\n",
    "    return head, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, data_gyro = get_gyroscope_data(gyropath, intr_gyro)\n",
    "#take every alternate row of gyro data\n",
    "data_gyro = data_gyro[::2]\n",
    "print(head, data_gyro.shape)\n",
    "head, data_acc = get_accelerometer_data(accpath, intr_acc)\n",
    "print(head, data_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_max = bisect(data_gyro[:,0], data_acc[-1,0])\n",
    "ind_min = bisect(data_gyro[:,0], data_acc[0,0])\n",
    "data_gyro = data_gyro[ind_min:ind_max,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100/(data_gyro[100,0] - data_gyro[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create interpolators\n",
    "acc_interpolator = interp1d(data_acc[:,0], data_acc[:,1:], axis=0)\n",
    "#interpolate at precise timesteps\n",
    "acc_interp = acc_interpolator(data_gyro[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_IMU_readings(head, imu_mat, imu_path):\n",
    "    with open(imu_path, \"w\") as fp:\n",
    "        fp.write(head)\n",
    "        for idr in range(imu_mat.shape[0]):\n",
    "            reading = imu_mat[idr]\n",
    "            ts = str(int(reading[0]))\n",
    "            lsr = [str(x) for x in reading[1:]]\n",
    "            lsr = [ts] + lsr\n",
    "            line = \",\".join(lsr) + \"\\n\"\n",
    "            fp.write(line)\n",
    "    print(\"Done.\")\n",
    "\n",
    "#imu hed\n",
    "head = \"#timestamp [ns],w_RS_S_x [rad s^-1],w_RS_S_y [rad s^-1],w_RS_S_z [rad s^-1],a_RS_S_x [m s^-2],a_RS_S_y [m s^-2],a_RS_S_z [m s^-2]\\n\"\n",
    "imu_mat = np.concatenate([data_gyro, acc_interp], axis=1)\n",
    "imu_mat[:,0] *= 1e9\n",
    "\n",
    "write_IMU_readings(head, imu_mat, imu_path)\n",
    "\n",
    "imu_dir2 = os.path.join(outpath, \"mav0/imu0/\")\n",
    "\n",
    "if not os.path.exists(imu_dir2):\n",
    "    print(\"Creating dir: \"+imu_dir2)\n",
    "    os.makedirs(imu_dir2)\n",
    "\n",
    "imu_path2 = os.path.join(imu_dir2, \"data.csv\")\n",
    "write_IMU_readings(head, imu_mat, imu_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imu_mat[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rgb = get_rgb_data(rgbpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_path = os.path.join(outpath, \"mav0/cam0/data/\")\n",
    "\n",
    "if not os.path.exists(cam_path):\n",
    "    print(\"Creating dir: \"+cam_path)\n",
    "    os.makedirs(cam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(timestamp_path, \"w\") as fp:\n",
    "    for idx,line in enumerate(data_rgb):\n",
    "        tsstr = str(int(line[0]*1e9))\n",
    "        fp.write(tsstr+\"\\n\")\n",
    "        fname = tsstr+\".png\"\n",
    "        dst = os.path.join(cam_path, fname)\n",
    "        src = os.path.join(inpath, line[2])\n",
    "        command = \"ln -sf \"+src+\" \"+dst\n",
    "        os.system(command)\n",
    "        if (idx+1)%100 == 0:\n",
    "            print(idx+1,len(data_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/media/prakhar/BIG_BAG/Capstone/Loris_monoi/office1-1/mav0/cam0/data/1560000083949196032.pn\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viPy3_CMU",
   "language": "python",
   "name": "vipy3_cmu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
